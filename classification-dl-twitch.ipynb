{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8996f618-cdc4-4f9e-abd8-3d84e9973ac0",
   "metadata": {},
   "source": [
    "# Node classification in networks using deep learning with Graph Neural Networks\n",
    "\n",
    "In this section we illustrate how to use deep learning methods, in specific, Graph Neural Networks (GNN), to perform node classification in networks.\n",
    "\n",
    "GNNs are particularly effective for tasks like node classification, where the goal is to predict the labels of nodes in a network. Unlike traditional network libraries such as NetworkX, which cannot handle node features directly, GNNs are designed to leverage both the network structure and the node features, enabling them to capture complex relationships and dependencies within the network more effectively.\n",
    "\n",
    "We will use the PyTorch Geometric (PyG) library `torch_geometric`. PyG is built upon PyTorch and is specifically tailored to allow creating and training GNNs for a wide range of tasks related to structured data, such as complex networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc116ba-25f5-44f8-b4b3-3048f93cac01",
   "metadata": {},
   "source": [
    "To demonstrate, we will use the Twitch Gamer networks dataset [1]. Twitch is an online platform that focuses on video game live streaming [2]. \n",
    "The dataset contains user-user networks for 6 different languages. Nodes correspond to Twitch users, and links correspond to mutual friendships. Node features are games liked, location and streaming habits. All networks have the same set of node features. In addition, each node is labelled as 1 for using the language associated with the network it is in, and 0 for not. Our task is binary classification of whether a user uses the language associated with the network.\n",
    "\n",
    "```\n",
    "langs = {\"DE\", \"EN\", \"ES\", \"FR\", \"PT\", \"RU\"}\n",
    "```\n",
    "\n",
    "[1] \"Multi-Scale Attributed Node Embedding\", Rozemberczki et al., https://arxiv.org/pdf/1909.13021\n",
    "\n",
    "[2] https://www.twitch.tv/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53460017-6da0-4d13-a084-173175f8bb75",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d4ada3-83a9-42bb-a9a5-d6edd041cb51",
   "metadata": {},
   "source": [
    "The Twitch dataset we use is available as in the ```torch_geometric``` package [1]. Thus, we can load it to PyG with ease. We use the German network `DE` as an example.\n",
    "\n",
    "[1] https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.Twitch.html#torch_geometric.datasets.Twitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497c8bee-642c-4b3b-8918-0d8473d8802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yfiua/Library/Python/3.9/lib/python/site-packages/torch_geometric/data/dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
      "/Users/yfiua/Library/Python/3.9/lib/python/site-packages/torch_geometric/data/dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
      "/Users/yfiua/Library/Python/3.9/lib/python/site-packages/torch_geometric/io/fs.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Twitch\n",
    "\n",
    "dataset = Twitch(root='./data/twitch', name='DE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5add45-51ac-4c95-a9f3-05a3b8d3fc89",
   "metadata": {},
   "source": [
    "### Show statistics of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "430e34ff-20cb-4677-b37c-6f06e94c134c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 9498\n",
      "Number of edges: 315774\n"
     ]
    }
   ],
   "source": [
    "# number of nodes and edges\n",
    "N, M = dataset[0].num_nodes, dataset[0].num_edges\n",
    "print(f'Number of nodes: {N}')\n",
    "print(f'Number of edges: {M}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "459db52e-a05a-4654-8efe-9cfc34733b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2367, -0.2307, -0.1605,  ..., -0.6348, -0.2558, -0.1839],\n",
       "         [-0.2367, -0.2307, -0.1605,  ..., -0.6348, -0.2558, -0.1839],\n",
       "         [-0.2354, -0.2210, -0.1605,  ..., -0.6348, -0.2490, -0.1839],\n",
       "         ...,\n",
       "         [-0.2367, -0.2307, -0.1605,  ..., -0.6348, -0.2558, -0.1839],\n",
       "         [-0.2367, -0.2307, -0.1605,  ..., -0.6348, -0.2558, -0.1839],\n",
       "         [-0.2367, -0.2307, -0.1605,  ..., -0.6348, -0.2558, -0.1810]]),\n",
       " tensor([0, 1, 1,  ..., 1, 0, 0]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the node features and labels\n",
    "dataset[0].x, dataset[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6228276-772e-47dd-8f1e-a8fee62f6bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of node features: 128\n",
      "Number of node classes: 2\n"
     ]
    }
   ],
   "source": [
    "# number of node features and node classes\n",
    "print('Number of node features:', dataset.num_node_features)\n",
    "print('Number of node classes:', dataset.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55390326-5f11-4590-a2f6-dce9341313a8",
   "metadata": {},
   "source": [
    "## Split training and test data\n",
    "\n",
    "We split the node labels `y` into two sets: training and test. We do this by creating two \"masks\", which are boolean tensors that specify which nodes are included in each set.\n",
    "\n",
    "The training set is used to train the GNN model, thus it is visible to the model during the training phase. The test dataset is not visible to the model during the training phase, and will only be used to evaluate the model.\n",
    "\n",
    "Note in our setting, the network structure and the node features are visible to the model during the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02ebc600-c40a-4d28-9467-d07f6a3fd956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param: define the size of the training dataset\n",
    "train_size = .8\n",
    "\n",
    "# Generate random permutation of node indices\n",
    "perm = torch.randperm(N)\n",
    "\n",
    "# Select train and test nodes\n",
    "train_idx = perm[: int(train_size * N)]\n",
    "test_idx = perm[int(train_size * N) :]\n",
    "\n",
    "# Initialize train_mask and test_mask with False\n",
    "train_mask = torch.zeros(N, dtype=torch.bool)\n",
    "test_mask = torch.zeros(N, dtype=torch.bool)\n",
    "\n",
    "# Set the selected indices to True\n",
    "train_mask[train_idx] = True\n",
    "test_mask[test_idx] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b08a0-9347-4d1b-a4fb-f3a200e8837b",
   "metadata": {},
   "source": [
    "## Define a simply Graph Convolutional Network (GCN) model\n",
    "\n",
    "Now we define a two-layer GCN model. The model consists of two graph convolutional layers with 32 filters, a dropout layer, and ReLU activations.\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* Graph convolution layers: Applied to the network with node features `x`. They are used to aggregate neighbouring node features in a network. This aggregation is essential for capturing the local structure and relationships within a network. In PyG it is implemented as `torch_geometric.nn.GCNConv`. Note a graph convolutional layer can also be applied to the network with aggregated node features.\n",
    "* ReLU Activation: Applied after the first convolution layer. This is to capture the non-linearity in the data.\n",
    "* Dropout: Applied after the first convolution layer. The dropout layer is used to prevent overfitting.\n",
    "\n",
    "Parameters:\n",
    "```\n",
    "Learning rate: 0.01\n",
    "Dropout: 0.5\n",
    "Weight decay: 0.0005\n",
    "Filters per layer: 32 (hidden channels)\n",
    "Number of epochs: 200\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed2cb74a-2da6-4012-91b2-c3eb7b2cb8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# params\n",
    "lr = .01\n",
    "weight_decay=5e-4\n",
    "p_dropout = .5\n",
    "num_filters = 32\n",
    "num_epochs = 200\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, num_filters)\n",
    "        self.conv2 = GCNConv(num_filters, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=p_dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e10187-28e8-45ce-8061-1e49216dc1c5",
   "metadata": {},
   "source": [
    "The two graph convolution layers are defined in the `__init__(self)` function.\n",
    "\n",
    "Function `forward(self, data)` defines the GCN structure, whose input `data` contains the node features `data.x` and the network structure as captured in `data.edge_index`. Going through the first graph convolutional layer, the ReLU activation, the dropout layer, and the second graph convolutional layer, the output of the GCN is the logorithm of the softmax function, which can be used to compute the probability of a node belonging to each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e648e0c7-cd05-43e8-96ac-0ba978b6823d",
   "metadata": {},
   "source": [
    "## Train the GCN model\n",
    "With the dataset prepared and GCN classification model defined, we now can train the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a090165-4533-40b1-aa2b-f9b4858f7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best device to run on\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d30da36e-b77c-465a-bc6c-b820656053b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the model and data to the device\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "train_mask = train_mask.to(device)\n",
    "test_mask = test_mask.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8214d60f-d618-474c-9171-d39da79b3b61",
   "metadata": {},
   "source": [
    "In each epoch, the optimizer updates the weights in our GCN model to improve its predictions on the training data by minimizing the loss function. In our case, the loss function is the Negative Log-Likelihood (NLL) function, which is particularly suited for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16eb82f0-f796-48d6-97ee-24c5c98d9ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.7230\n",
      "Epoch: 010, Loss: 0.6047\n",
      "Epoch: 020, Loss: 0.5861\n",
      "Epoch: 030, Loss: 0.5754\n",
      "Epoch: 040, Loss: 0.5683\n",
      "Epoch: 050, Loss: 0.5644\n",
      "Epoch: 060, Loss: 0.5591\n",
      "Epoch: 070, Loss: 0.5548\n",
      "Epoch: 080, Loss: 0.5500\n",
      "Epoch: 090, Loss: 0.5473\n",
      "Epoch: 100, Loss: 0.5441\n",
      "Epoch: 110, Loss: 0.5407\n",
      "Epoch: 120, Loss: 0.5360\n",
      "Epoch: 130, Loss: 0.5350\n",
      "Epoch: 140, Loss: 0.5311\n",
      "Epoch: 150, Loss: 0.5309\n",
      "Epoch: 160, Loss: 0.5295\n",
      "Epoch: 170, Loss: 0.5284\n",
      "Epoch: 180, Loss: 0.5247\n",
      "Epoch: 190, Loss: 0.5212\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[train_mask], data.y[train_mask])\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e259629-0819-4f05-aa89-214bc347f46e",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14a0cf7-7103-4308-bcd8-f1a3918d847b",
   "metadata": {},
   "source": [
    "To evaluate the GCN classification model we just trained, we first use it to predict the labels of the nodes in the test set.\n",
    "\n",
    "Remember: technically the output of the model is in the form of `log_softmax`, so we need to convert it to either binary classes or probabilities, depending on our needs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "999aa5dc-e7cf-448d-9e67-49e9e70c9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "\n",
    "y_true = data.y[test_mask].cpu().numpy()\n",
    "y_pred = pred[test_mask].cpu().numpy()\n",
    "y_proba = torch.exp(model(data))[test_mask].cpu().detach().numpy()[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6286f3c7-2599-43d9-b862-770ab3e78ca9",
   "metadata": {},
   "source": [
    "Check the predicted node classes and probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53afb174-88f7-48f1-b0e9-3e8f82fbe359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bf03f96-536f-4ed2-9e34-ac3f6fcdff8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18113099, 0.60741115, 0.4456026 , ..., 0.859128  , 0.59309757,\n",
       "       0.7267557 ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eaa543-d200-4786-9aa3-36ee30841a26",
   "metadata": {},
   "source": [
    "We now compare the GCN model's prediction with the ground truth, and calculate the following metrics on the result using the `sklearn` library.\n",
    "\n",
    "* Accuracy: a general measure of how often the model is correct.\n",
    "* Precision: focuses on the quality of positive predictions.\n",
    "* Recall: focuses on capturing all actual positives.\n",
    "* F1-Score: provides a balance between precision and recall.\n",
    "* ROC AUC: measures the model's ability to distinguish between classes over various thresholds, providing a comprehensive performance indicator.\n",
    "\n",
    "These metrics collectively provide a detailed view of the model’s performance, helping to understand its strengths and weaknesses in predicting the labels for the nodes in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b180a7c8-ce0a-4441-98fe-5c04317eb38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6653\n",
      "Precision: 0.6525\n",
      "Recall: 0.6370\n",
      "F1-score: 0.6386\n",
      "ROC AUC: 0.7246\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = (y_pred == y_true).sum() / test_mask.sum().item()\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "roc_auc = roc_auc_score(y_true, y_proba)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "print(f'ROC AUC: {roc_auc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
