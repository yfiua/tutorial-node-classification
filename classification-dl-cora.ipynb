{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ee605d-de55-4432-8784-f172793ade36",
   "metadata": {},
   "source": [
    "# Solution 2: Node classification with PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c29eb1e-e1e5-4fd6-8af0-297e046d4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53460017-6da0-4d13-a084-173175f8bb75",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d4ada3-83a9-42bb-a9a5-d6edd041cb51",
   "metadata": {},
   "source": [
    "The Cora dataset we will use is available as in the ```torch_geometric``` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497c8bee-642c-4b3b-8918-0d8473d8802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yfiua/Library/Python/3.9/lib/python/site-packages/torch_geometric/data/dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
      "/Users/yfiua/Library/Python/3.9/lib/python/site-packages/torch_geometric/data/dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
      "/Users/yfiua/Library/Python/3.9/lib/python/site-packages/torch_geometric/io/fs.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='./data/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5add45-51ac-4c95-a9f3-05a3b8d3fc89",
   "metadata": {},
   "source": [
    "### Show statistics of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add43884-cddd-41a2-9c82-af6ea3f4d08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planetoid (#graphs=1):\n",
      "+------------+----------+----------+\n",
      "|            |   #nodes |   #edges |\n",
      "|------------+----------+----------|\n",
      "| mean       |     2708 |    10556 |\n",
      "| std        |      nan |      nan |\n",
      "| min        |     2708 |    10556 |\n",
      "| quantile25 |     2708 |    10556 |\n",
      "| median     |     2708 |    10556 |\n",
      "| quantile75 |     2708 |    10556 |\n",
      "| max        |     2708 |    10556 |\n",
      "+------------+----------+----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yfiua/Library/Python/3.9/lib/python/site-packages/torch_geometric/data/summary.py:34: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1808.)\n",
      "  std=data.std().item(),\n"
     ]
    }
   ],
   "source": [
    "# number of nodes and edges\n",
    "dataset.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6228276-772e-47dd-8f1e-a8fee62f6bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# number of node classes\n",
    "print(dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67645481-bf9a-479f-b02c-45c8e5dd4867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1433\n"
     ]
    }
   ],
   "source": [
    "# number of node features\n",
    "print(dataset.num_node_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b09c6-3a7a-4645-aefb-7ec37a24ac9b",
   "metadata": {},
   "source": [
    "### Train and test split\n",
    "\n",
    "Unlike our previous cases, here the `train_mask` and the `test_mask` are predefined. Note: not all nodes appear in the two sets.\n",
    "\n",
    "You can alternatively redefine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dacf51e-3ff8-4d09-a5b3-7e33e5c87ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mask:  tensor([ True,  True,  True,  ..., False, False, False]) . Training set size:  140\n",
      "Test mask:  tensor([False, False, False,  ...,  True,  True,  True])  . Test set size:  1000\n"
     ]
    }
   ],
   "source": [
    "print('Train mask: ', dataset[0].train_mask, '. Training set size: ', np.count_nonzero(dataset[0].train_mask))\n",
    "print('Test mask: ', dataset[0].test_mask,  ' . Test set size: ', np.count_nonzero(dataset[0].test_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b08a0-9347-4d1b-a4fb-f3a200e8837b",
   "metadata": {},
   "source": [
    "## Define and train a simply Graph Convolutional Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed2cb74a-2da6-4012-91b2-c3eb7b2cb8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a090165-4533-40b1-aa2b-f9b4858f7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best device to run on\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d30da36e-b77c-465a-bc6c-b820656053b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the model and data to the device\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16eb82f0-f796-48d6-97ee-24c5c98d9ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e259629-0819-4f05-aa89-214bc347f46e",
   "metadata": {},
   "source": [
    "## Node classification and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14a0cf7-7103-4308-bcd8-f1a3918d847b",
   "metadata": {},
   "source": [
    "To evaluate the Graph Convolutional Network model we just trained, we use it to predict the labels of the nodes in the test set, and compare the results with the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "999aa5dc-e7cf-448d-9e67-49e9e70c9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "\n",
    "y_true = data.y[data.test_mask].cpu().numpy()\n",
    "y_pred = pred[data.test_mask].cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e34f490-fc21-40ff-aef9-04bfe3151ed6",
   "metadata": {},
   "source": [
    "We print different metrics using the `classification_report` function in `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a09ae70d-1942-49a5-b7b2-8d8a8a6ad71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance (GCN): \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.73      0.70       130\n",
      "           1       0.78      0.90      0.84        91\n",
      "           2       0.87      0.92      0.90       144\n",
      "           3       0.90      0.75      0.82       319\n",
      "           4       0.79      0.83      0.81       149\n",
      "           5       0.78      0.75      0.76       103\n",
      "           6       0.67      0.84      0.74        64\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.78      0.82      0.80      1000\n",
      "weighted avg       0.81      0.80      0.80      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('Performance (GCN): \\n', classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
