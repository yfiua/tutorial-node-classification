{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b48a56e-5eb9-4911-bf2e-988eefb8bf81",
   "metadata": {},
   "source": [
    "# Node classification in networks using NetworkX\n",
    "\n",
    "In this section we illustrate how to use the NetworkX library to perform node classification in networks. The NetworkX library in Python is a powerful tool for working with complex networks and can be used to perform node classification.\n",
    "\n",
    "To demonstrate, we will use the Airports dataset [1], which contains three networks `{'usa', 'brazil', 'europe'}` in which nodes represent airports and edges represent the existence of flights between airports. In addition, node labels correspond to airport activity levels `{0, 1, 2, 3}`.  Our task is then classifying the airport activity levels in the network.\n",
    "\n",
    "[1] \"struc2vec: Learning Node Representations from Structural Identity\", Ribeiro et al., https://arxiv.org/abs/1704.03165\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e73d89-b3b4-4996-bccc-87b33e09c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from networkx.algorithms import node_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770fd029-e33f-49db-b69c-ec74b8167e98",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2285e1cb-f76a-4be7-a00a-259bcf145cb7",
   "metadata": {},
   "source": [
    "The Airport dataset is available online [1]. If you have run the preparation script `prep.sh`, the dataset should appear in `data/airports/`. Otherwise you can download it manually. We will use the `usa` network through this section.\n",
    "\n",
    "[1] https://github.com/leoribeiro/struc2vec/tree/master/graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "997693f2-ae95-40b0-ac64-194074ff159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "data_dir = 'data/airports/'\n",
    "network = 'usa'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928ef10e-8268-4abc-ace1-1ff24d1bf683",
   "metadata": {},
   "source": [
    "### Load edge info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c9cb81b-8b7f-427d-9d2a-d1f069d4de13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12343</td>\n",
       "      <td>12129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13277</td>\n",
       "      <td>11996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13796</td>\n",
       "      <td>13476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15061</td>\n",
       "      <td>14559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14314</td>\n",
       "      <td>12889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13594</th>\n",
       "      <td>13303</td>\n",
       "      <td>10747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13595</th>\n",
       "      <td>13029</td>\n",
       "      <td>12892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13596</th>\n",
       "      <td>13930</td>\n",
       "      <td>11618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13597</th>\n",
       "      <td>12278</td>\n",
       "      <td>11423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13598</th>\n",
       "      <td>14747</td>\n",
       "      <td>11267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13599 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       source  target\n",
       "0       12343   12129\n",
       "1       13277   11996\n",
       "2       13796   13476\n",
       "3       15061   14559\n",
       "4       14314   12889\n",
       "...       ...     ...\n",
       "13594   13303   10747\n",
       "13595   13029   12892\n",
       "13596   13930   11618\n",
       "13597   12278   11423\n",
       "13598   14747   11267\n",
       "\n",
       "[13599 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgelist = pd.read_csv(os.path.join(data_dir, f\"{network}-airports.edgelist\"), sep=' ', header=None, names=[\"source\", \"target\"])\n",
    "edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba729e0-f170-42ea-97dd-0f4ede64cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to use an undirected graph here because the node classification algorithms in nx do not support directed graphs\n",
    "G = nx.from_pandas_edgelist(edgelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b478e931-cfa9-4920-a2b0-c4ed30fe12be",
   "metadata": {},
   "source": [
    "### Load node labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca7a1af-6fda-4fb1-8919-fa70d55d21af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10243</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>12278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>12280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>14332</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>10237</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>16353</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1190 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       node  label\n",
       "0     10241      1\n",
       "1     10243      2\n",
       "2     10245      0\n",
       "3     16390      1\n",
       "4     10247      1\n",
       "...     ...    ...\n",
       "1185  12278      0\n",
       "1186  12280      0\n",
       "1187  14332      3\n",
       "1188  10237      2\n",
       "1189  16353      2\n",
       "\n",
       "[1190 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes = pd.read_csv(os.path.join(data_dir, f\"labels-{network}-airports.txt\"), sep=' ')\n",
    "df_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c747649-835c-4b05-8ef2-122ec2c5b3b7",
   "metadata": {},
   "source": [
    "## Split training and test data\n",
    "\n",
    "We split the node labels into two sets: training and test using function `train_test_split()` from the `sklearn` library.\n",
    "\n",
    "The training set is used to train the node classifiers, thus it is visible to the model during the training phase. The test dataset is not visible to the model during the training phase, and will only be used to evaluate the classifiers.\n",
    "\n",
    "Note in our setting, the whole network structure is visible to the model during the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2657ecce-cba7-413a-960b-63a1c82506e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param: define the size of the training dataset\n",
    "train_size = 0.8\n",
    "df_train, df_test = train_test_split(df_nodes, train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "760c0864-903a-4b11-bf75-1ae516c3dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_ids_train, node_ids_test = df_train.iloc[:, 0].values, df_test.iloc[:, 0].values\n",
    "labels_train, labels_test = df_train.iloc[:, -1].values.astype(str), df_test.iloc[:, -1].values.astype(str)\n",
    "data_train = dict(zip(node_ids_train, labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a687722-010e-4964-929d-d53838dcda30",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, data_train, name=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22865f5-d076-4e00-886b-6207502a2b82",
   "metadata": {},
   "source": [
    "## Perform node classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0a3bdd-3f83-436f-9211-9282fdf5bcc1",
   "metadata": {},
   "source": [
    "Now we perform node classification using the built-in Harmonic Function method in NetworkX.\n",
    "\n",
    "* Zhu, X., Ghahramani, Z., & Lafferty, J. (2003, August). Semi-supervised learning using gaussian fields and harmonic functions. In ICML (Vol. 3, pp. 912-919)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47837b34-cdf2-4b37-843a-85b659effbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_hf = node_classification.harmonic_function(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da5b4ae-c6b8-4fcd-9c40-ad1f1354ad2c",
   "metadata": {},
   "source": [
    "The result contains the labels (predicted or ground truth) of all nodes. For example, the labels of the first five nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c511a9f-2e59-44bc-bf14-367030d3ebd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '0', '0', '0']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check part of the result\n",
    "result_hf[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c5550f-9f36-47d7-9a05-0556153f2c06",
   "metadata": {},
   "source": [
    "Similarly, we can perform node classification using the built-in Local and Global Consistency method.\n",
    "\n",
    "* Zhou, D., Bousquet, O., Lal, T. N., Weston, J., & Schölkopf, B. (2004). Learning with local and global consistency. Advances in neural information processing systems, 16(16), 321-328."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bb66b27-b96b-4295-ac84-11b66e833a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lgc = node_classification.local_and_global_consistency(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a0de4-aba4-49d3-b48e-b7b13b6ef1f5",
   "metadata": {},
   "source": [
    "The result contains the labels (predicted or ground truth) of all nodes. For example, the labels of the first five nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d647e67-eea6-4985-804c-dffe382fa3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '0', '0', '0', '0']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check part of the result\n",
    "result_lgc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ecad08-5d7b-4ced-9db8-f5dc369ac22a",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c99ae788-6c7f-4f2c-a23b-db9b7463c773",
   "metadata": {},
   "source": [
    "To evaluate the results of the classification, we fetch the labels of the nodes in the test set.\n",
    "\n",
    "We then compare the redicted node labels with the ground truth, and calculate the following metrics on the result using the `sklearn` library.\n",
    "\n",
    "* Accuracy: a general measure of how often the model is correct.\n",
    "* Precision: focuses on the quality of positive predictions.\n",
    "* Recall: focuses on capturing all actual positives.\n",
    "* F1-Score: provides a balance between precision and recall.\n",
    "\n",
    "Since we have a multi-class classification problem, we also calculate the average precision, average recall, and average F1-score for all classes. These metrics collectively provide a detailed view of the model’s performance, helping to understand its strengths and weaknesses in predicting the labels for the nodes in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5c54e0-e42f-4659-aea4-4a287ed990e7",
   "metadata": {},
   "source": [
    "### Evaluation of the \"Harmonic Function\" classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "599e0a3e-0fb0-4fe5-85a4-4bd8fd06a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_result_hf = dict(zip(list(G), result_hf))\n",
    "labels_pred_hf = [ dict_result_hf.get(id) for id in node_ids_test ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82be9718-5c8d-4498-84f3-df838211ce00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the \"Harmonic Function\" classifier\n",
      "Accuracy: 0.3739\n",
      "                  Precision    Recall  F1 Score  Support\n",
      "Activity Level 0   0.299363  0.959184  0.456311       49\n",
      "Activity Level 1   0.400000  0.431373  0.415094       51\n",
      "Activity Level 2   0.714286  0.238095  0.357143       63\n",
      "Activity Level 3   1.000000  0.066667  0.125000       75\n",
      "Average Precision: 0.6034\n",
      "Average Recall: 0.4238\n",
      "Average F1-score: 0.3384\n"
     ]
    }
   ],
   "source": [
    "print('Performance of the \"Harmonic Function\" classifier')\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy = accuracy_score(labels_test, labels_pred_hf)\n",
    "\n",
    "# calculate precision, recall, F1 score, and support\n",
    "precision, recall, f1, support = precision_recall_fscore_support(labels_test, labels_pred_hf, average=None)\n",
    "df_eval = pd.DataFrame({\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1,\n",
    "    'Support': support\n",
    "}, index=['Activity Level 0', 'Activity Level 1', 'Activity Level 2', 'Activity Level 3'])\n",
    "\n",
    "# calculate average precision, average recall, and average F1 score\n",
    "avg_precision = precision_score(labels_test, labels_pred_hf, average='macro')\n",
    "avg_recall = recall_score(labels_test, labels_pred_hf, average='macro')\n",
    "avg_f1 = f1_score(labels_test, labels_pred_hf, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "print(df_eval)\n",
    "\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n",
    "print(f'Average Recall: {avg_recall:.4f}')\n",
    "print(f'Average F1-score: {avg_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cc7f93-be2f-47b2-9bd0-eec7f1c7fde5",
   "metadata": {},
   "source": [
    "### Evaluation of the \"Local and Global Consistency\" classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dffe5b7-a64d-4498-89bb-78d7899a6e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_result_lgc = dict(zip(list(G), result_lgc))\n",
    "labels_pred_lgc = [ dict_result_lgc.get(id) for id in node_ids_test ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5147371-15f6-4fcf-8bf7-ab05618df7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the \"Local and Global Consistency\" classifier\n",
      "Accuracy: 0.3403\n",
      "                  Precision    Recall  F1 Score  Support\n",
      "Activity Level 0   0.311258  0.959184  0.470000       49\n",
      "Activity Level 1   0.328947  0.490196  0.393701       51\n",
      "Activity Level 2   0.800000  0.126984  0.219178       63\n",
      "Activity Level 3   1.000000  0.013333  0.026316       75\n",
      "Average Precision: 0.6101\n",
      "Average Recall: 0.3974\n",
      "Average F1-score: 0.2773\n"
     ]
    }
   ],
   "source": [
    "print('Performance of the \"Local and Global Consistency\" classifier')\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy = accuracy_score(labels_test, labels_pred_lgc)\n",
    "\n",
    "# calculate precision, recall, F1 score, and support\n",
    "precision, recall, f1, support = precision_recall_fscore_support(labels_test, labels_pred_lgc, average=None)\n",
    "df_eval = pd.DataFrame({\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1,\n",
    "    'Support': support\n",
    "}, index=['Activity Level 0', 'Activity Level 1', 'Activity Level 2', 'Activity Level 3'])\n",
    "\n",
    "# calculate average precision, average recall, and average F1 score\n",
    "avg_precision = precision_score(labels_test, labels_pred_lgc, average='macro')\n",
    "avg_recall = recall_score(labels_test, labels_pred_lgc, average='macro')\n",
    "avg_f1 = f1_score(labels_test, labels_pred_lgc, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}', )\n",
    "\n",
    "print(df_eval)\n",
    "\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n",
    "print(f'Average Recall: {avg_recall:.4f}')\n",
    "print(f'Average F1-score: {avg_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d77ea2-5029-4e3a-abb5-473c44def626",
   "metadata": {},
   "source": [
    "To summarize, the two classifiers have overall low performance as indicated by the low average F1-score. They have higher precision for high activity-level airports, and higher recall for low activity-level airports. This indicates that the classifiers tend to underestimate the activity level."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
